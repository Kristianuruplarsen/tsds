{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Analyzing Text\n",
    "## Characterizing the R and Python Communities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import codecs\n",
    "import requests\n",
    "import wordcloud\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls Snorre's expore_regex script from github \n",
    "# useful to set up an explorer that can be used to iteratively\n",
    "# find good regular expressions\n",
    "#\n",
    "# use the module to develop the pattern and finally use the .report() method to document your process. \n",
    "\n",
    "with open('explore_regex.py','w') as f:\n",
    "    f.write(requests.get('https://raw.githubusercontent.com/snorreralund/explore_regex/master/explore_regex.py').text)\n",
    "    \n",
    "import explore_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "# Load overflow data\n",
    "overflow_df = pd.read_csv('Posts_overflow.csv').dropna(subset = ['Body'])\n",
    "# Load the datascience data. \n",
    "datascience_df = pd.read_csv('Posts_ds.csv').dropna(subset = ['Body'])\n",
    "# load stats data\n",
    "stats_df = pd.read_csv('Posts_stats.csv').dropna(subset = ['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.11.1.1** _Cleaning_\n",
    "First task is as with any other data experience (especially text data): It needs Cleaning. Here we need to brush up on our string and scraping fundamentals: Regular expressions and BeautifulSoup.\n",
    "\n",
    "Before we apply BeatifulSoup to get the clean text from HTML. We need to do some \"pre-preprocessing\".\n",
    "We shall take advantage of the HTML tags to extract code from text.\n",
    "\n",
    "Extract the code segments using the HTML tag: \"<\\CODE>\", and put it into a separate columns for later analysis.\n",
    "\n",
    "- Design a regular expression that match anything inside a `<code></code>` html-tag. \n",
    "> _Hint:_ inspect some of the data to see exactly how the code is wrapped in the html.\n",
    "- Use it to extract it to another column.\n",
    "- Use it to remove the code from the Body column.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [This question will be in assignment 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 11.1.2** Extract comments within the code using regular expressions matching everything between a **#** and a **\\n** \n",
    "\n",
    "Later we shall use this to analyze properties of the comment in relation to the code (e.g. number of comments,  length). Specifically we need to define a regular expressions that extracts comment text from within the code segments, by matching anything after # until a newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_str = '#.*$'\n",
    "comment_regex = re.compile(comment_str, flags = re.DOTALL|re.UNICODE)\n",
    "\n",
    "overflow_df = extract_from_to_column(overflow_df, comment_regex, from_col = 'code', to_col = 'comments')\n",
    "datascience_df = extract_from_to_column(datascience_df, comment_regex, from_col = 'code', to_col = 'comments')\n",
    "stats_df = extract_from_to_column(stats_df, comment_regex, from_col = 'code', to_col = 'comments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 11.1.3**\n",
    "Now that the code is removed we can now use BeautifulSoup to Extract the text from the HTML.\n",
    "> *Hint:* To use BeautifulSoup to extract the text from the Body columns use  `.get_text()`.\n",
    "\n",
    "Inspect if the results are good by sampling a few examples and skimming them. Wrap it all in a function and run it on all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.1.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_text(df):    \n",
    "    df['text'] = df.Body.apply(lambda x: get_text(x))    \n",
    "    return df \n",
    "\n",
    "overflow_df    = extract_text(overflow_df)\n",
    "datascience_df = extract_text(datascience_df)\n",
    "stats_df       = extract_text(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.11.1.4** Finally Extract the individual tags from the Tags columns using regular expressions. \n",
    "- Design a regular expression that matches the characters and symbols within the <> brackets. <[symbolsgoeshere]>, and assign it to a column named `tags_l` that holds a list of tags. \n",
    "- Count the Tags and Visualize them using the WordCloud package (https://github.com/amueller/word_cloud ). See this simple example: https://github.com/amueller/word_cloud/blob/master/examples/simple.py \n",
    "> *Hint:* use the method: .generate_from_frequencies(). That takes a dictionary of strings and their counts as input.\n",
    "\n",
    "**Extra:** \n",
    "Visualize two tag sets:\n",
    "    - one that co-occur with the <r> tag\n",
    "    - and another for the <python>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [This question will be in assignment 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Filtering the data\n",
    "All analyses fundamentally depend on the way that the data was sampled. In this case I constructed a \"rough\" dataset, using a greedy matching of all R and Python patterns in the post and tags of the stackoverflow forums. Especially the matching of R was not completely unproblematic, and needs a re-iteration. \n",
    "\n",
    "There are two strategies here:\n",
    "- Work on a better Regular expression to match all instances of the R programming language and exclude false, if possible. \n",
    "- Or use the Tags column as a strategy for delimiting your data, using the userdefined Tags as qualifiers. Here it is about locating and delimiting which tags to include.\n",
    "    \n",
    "We will work on the latter strategy, but choices here could essentially have a profound effect on our results and could be part of a sensitivity analysis.\n",
    "\n",
    "A simple solution would be to Filter only Posts and \"children\" with tagged with \n",
    "- `<r>`\n",
    "- `<python>`\n",
    "\n",
    "However an initial analysis of the tagging behavior suggests that other programs and individual R packages are also used.\n",
    "\n",
    "To expand the tags for our sampling strategy we can use the same methodology as we shall use later for finding phrases and colocations. \n",
    "Here we shall use the PMI measure of association to expand our seeds.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ex.11.2.1** Locate Tags to be used for delimiting our population using the PMI measure of association between all tags co-occurring with the <r> tag. \n",
    "\n",
    "- Use the tag_l column and count all co-occuring tags.\n",
    "- *Hint:* You can use itertools.combinations(tag_list,2) to iterate through co-occurring pairs and count them. \n",
    "\n",
    "Although we could use a networkx undirected graph as datastructure, this is a little overkill when not doing more advanced network analysis. Instead use the builtin Counter module (collections.Counter) and count the tuple pair (tag,tag2). As we are not interested in the direction(although sequence might tell you something), remember to sort the tags before counting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.2.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_colocations(df):\n",
    "    tag_collocations = Counter()\n",
    "\n",
    "    for tags in df.tags_l:\n",
    "        for pair in itertools.combinations(tags,2):\n",
    "            # sort the pair\n",
    "            s_pair = sorted(pair)\n",
    "            tag_collocations[tuple(s_pair)] +=1\n",
    "        \n",
    "    return tag_collocations\n",
    "\n",
    "coloc_overflow = count_colocations(overflow_df)\n",
    "coloc_ds = count_colocations(datascience_df)\n",
    "coloc_stats = count_colocations(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 11.2.2** Define a function with 4 arguments (token_count1,token_count2,cooc, N): Where N is the number of tag occurences in the corpus, and cooc is the co-occurence count. Use this input to compute the following formula:\n",
    "$$\\operatorname{pmi}(x ; y) \\equiv \\log \\frac{p(x, y)}{p(x) p(y)}$$\n",
    "- Compute the PMI of all tag pairs with the the `<r>` tag present.\n",
    "- Inspect the top and the bottom to see how well the measure does.\n",
    "- Define a variable r_tags as a set() of tags learned by inspecting the top 50 pmi scored tags.   \n",
    "- Finally make it re-usable by wrapping the whole thing in a function that takes a list of tokens as input, and returns counters of individudual tokens, and co-occurring tokens along. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Answer to ex. 11.2.2 here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pmi(token_count_1, token_count_2, cooc, N):\n",
    "    co_p = cooc / N\n",
    "    p = token_count_1 / N\n",
    "    p2 = token_count_2 / N\n",
    "    return np.log2(co_p/(p*p2))\n",
    "\n",
    "\n",
    "def calculate_pmi_to_tag(df, tag = 'r'):\n",
    "    colocation_count = count_colocations(df)\n",
    "    overall_count = count_tags(df)\n",
    "    \n",
    "    # Get only the pairs containing `tag`\n",
    "    partners = [(sorted(pair,key=lambda x: x== tag )[0] ,count) for pair,count in colocation_count.items() if tag in pair]\n",
    "\n",
    "    # Count the total number of tag-pairs\n",
    "    N_tags = sum(overall_count.values())\n",
    "        \n",
    "    # Total number of tags of `tag`\n",
    "    n = overall_count[tag]\n",
    "    \n",
    "    pmis = list()\n",
    "    \n",
    "    for tag2, co in partners:\n",
    "        n2 = overall_count[tag2]\n",
    "        pmi = get_pmi(n, n2, co, N_tags)\n",
    "        pmis.append([pmi, n2, co])\n",
    "\n",
    "    collocations = pd.DataFrame(pmis,columns=['pmi','count','co_count'],index=[i for i,j in partners])\n",
    "        \n",
    "    return collocations\n",
    "\n",
    "\n",
    "r_collocations = calculate_pmi_to_tag(overflow_df, tag = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmi</th>\n",
       "      <th>count</th>\n",
       "      <th>co_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ggplot2</th>\n",
       "      <td>4.242703</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r-markdown</th>\n",
       "      <td>4.137210</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knitr</th>\n",
       "      <td>4.125237</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <td>4.125237</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legend</th>\n",
       "      <td>4.092816</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaflet</th>\n",
       "      <td>4.070096</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar-chart</th>\n",
       "      <td>4.070096</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>4.040348</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confidence-interval</th>\n",
       "      <td>4.040348</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data-analysis</th>\n",
       "      <td>3.999706</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>3.999706</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcpp</th>\n",
       "      <td>3.999706</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca</th>\n",
       "      <td>3.940813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression</th>\n",
       "      <td>3.940813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecasting</th>\n",
       "      <td>3.940813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregate</th>\n",
       "      <td>3.940813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ess</th>\n",
       "      <td>3.940813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>3.914817</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boxplot</th>\n",
       "      <td>3.900171</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply</th>\n",
       "      <td>3.884229</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>igraph</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vector</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical-data</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correlation</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heatmap</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glm</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matching</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rodbc</th>\n",
       "      <td>3.847703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>-0.523856</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oop</th>\n",
       "      <td>-0.595240</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-web-services</th>\n",
       "      <td>-0.595240</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multithreading</th>\n",
       "      <td>-0.619902</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>-0.628030</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image-processing</th>\n",
       "      <td>-0.691456</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiprocessing</th>\n",
       "      <td>-0.737259</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matlab</th>\n",
       "      <td>-0.907184</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anaconda</th>\n",
       "      <td>-1.022661</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jquery</th>\n",
       "      <td>-1.094811</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows</th>\n",
       "      <td>-1.094811</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mongodb</th>\n",
       "      <td>-1.094811</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrays</th>\n",
       "      <td>-1.118081</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bash</th>\n",
       "      <td>-1.129577</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>php</th>\n",
       "      <td>-1.163524</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqlite</th>\n",
       "      <td>-1.163524</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postgresql</th>\n",
       "      <td>-1.229112</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>database</th>\n",
       "      <td>-1.322222</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysql</th>\n",
       "      <td>-1.409685</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scipy</th>\n",
       "      <td>-1.544614</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tensorflow</th>\n",
       "      <td>-1.570149</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selenium</th>\n",
       "      <td>-1.966078</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c#</th>\n",
       "      <td>-2.146650</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>-2.176051</td>\n",
       "      <td>347</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas</th>\n",
       "      <td>-2.303313</td>\n",
       "      <td>379</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary</th>\n",
       "      <td>-2.691456</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib</th>\n",
       "      <td>-2.946713</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>-4.493687</td>\n",
       "      <td>5622</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>django</th>\n",
       "      <td>-4.789827</td>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>-5.101394</td>\n",
       "      <td>659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pmi  count  co_count\n",
       "ggplot2              4.242703    145       143\n",
       "r-markdown           4.137210     12        11\n",
       "knitr                4.125237     11        10\n",
       "subset               4.125237     22        20\n",
       "legend               4.092816      9         8\n",
       "leaflet              4.070096      8         7\n",
       "bar-chart            4.070096      8         7\n",
       "summary              4.040348      7         6\n",
       "confidence-interval  4.040348      7         6\n",
       "data-analysis        3.999706      6         5\n",
       "distance             3.999706      6         5\n",
       "rcpp                 3.999706      6         5\n",
       "pca                  3.940813      5         4\n",
       "logistic-regression  3.940813      5         4\n",
       "forecasting          3.940813      5         4\n",
       "aggregate            3.940813      5         4\n",
       "ess                  3.940813      5         4\n",
       "merge                3.914817     14        11\n",
       "boxplot              3.900171      9         7\n",
       "apply                3.884229     13        10\n",
       "igraph               3.847703     12         9\n",
       "vector               3.847703     20        15\n",
       "categorical-data     3.847703      4         3\n",
       "correlation          3.847703      8         6\n",
       "mean                 3.847703      4         3\n",
       "finance              3.847703      4         3\n",
       "heatmap              3.847703      4         3\n",
       "glm                  3.847703      4         3\n",
       "matching             3.847703      4         3\n",
       "rodbc                3.847703      4         3\n",
       "...                       ...    ...       ...\n",
       "javascript          -0.523856    138         5\n",
       "oop                 -0.595240     29         1\n",
       "amazon-web-services -0.595240     29         1\n",
       "multithreading      -0.619902     59         2\n",
       "linux               -0.628030     89         3\n",
       "image-processing    -0.691456     31         1\n",
       "multiprocessing     -0.737259     32         1\n",
       "matlab              -0.907184     36         1\n",
       "anaconda            -1.022661     39         1\n",
       "jquery              -1.094811     41         1\n",
       "windows             -1.094811     82         2\n",
       "mongodb             -1.094811     41         1\n",
       "arrays              -1.118081    125         3\n",
       "bash                -1.129577     42         1\n",
       "php                 -1.163524     43         1\n",
       "sqlite              -1.163524     43         1\n",
       "postgresql          -1.229112     45         1\n",
       "database            -1.322222     48         1\n",
       "mysql               -1.409685    102         2\n",
       "scipy               -1.544614     56         1\n",
       "tensorflow          -1.570149    114         2\n",
       "selenium            -1.966078     75         1\n",
       "c#                  -2.146650     85         1\n",
       "java                -2.176051    347         4\n",
       "pandas              -2.303313    379         4\n",
       "dictionary          -2.691456    124         1\n",
       "matplotlib          -2.946713    148         1\n",
       "python              -4.493687   5622        13\n",
       "django              -4.789827    531         1\n",
       "android             -5.101394    659         1\n",
       "\n",
       "[426 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_collocations = r_collocations[~(r_collocations['count']==r_collocations['co_count'])]\n",
    "r_collocations.sort_values('pmi', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
